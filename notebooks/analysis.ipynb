{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9df4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODELS_DIR = Path().parent / \"models\"\n",
    "EXPERIMENTS_DIR = Path().parent / \"experiments\"\n",
    "BASE_DATA_DIR = Path().resolve().parent / \".cache\" / \"huggingface\" / \"datasets\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fca41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from dataset_loading import dataset\n",
    "\n",
    "mnist = dataset.get_dataset(name=\"mnist\", preprocess=True, to_tensor=False, flatten=False, resize=28, class_limit=10)\n",
    "train_mnist = mnist[0][\"train\"]\n",
    "test_mnist = mnist[0][\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98870023",
   "metadata": {},
   "source": [
    "### VAE LATENT SPACE ANALYSIS UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc64593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from utils.vae_net import VAE\n",
    "\n",
    "# Get trained VAE\n",
    "ckpt = torch.load(MODELS_DIR / \"5_epochs\" / \"mnist_head_10.pth\", map_location=\"cuda\")\n",
    "vae_mnist = VAE(w=28, h=28, latent_dim=10, channels=1)\n",
    "\n",
    "vae_mnist.load_state_dict(ckpt[\"hyper_state_dict\"])\n",
    "vae_mnist.to(\"cuda\")\n",
    "vae_mnist.eval()\n",
    "\n",
    "# extract samples from TEST set 10 samples from class 0,1,3, as we don't want to check memorization but generalization of gemotric shapes\n",
    "test_mnist_parquet = pd.DataFrame(test_mnist)\n",
    "selected_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "samples_per_class = 200  # or None for all\n",
    "\n",
    "mus_mnist = []\n",
    "labels_mnist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for c in selected_classes:\n",
    "        rows = test_mnist_parquet[test_mnist_parquet[\"label\"] == c]\n",
    "        rows = rows.sample(n=min(samples_per_class, len(rows)), random_state=42)\n",
    "\n",
    "        imgs = np.stack(rows[\"image\"].values)\n",
    "        imgs = torch.tensor(imgs).unsqueeze(1).float().to(\"cuda\") / 255.0\n",
    "\n",
    "        _, mu_mnist, _ = vae_mnist(imgs)\n",
    "        mus_mnist.append(mu_mnist.cpu().numpy())\n",
    "        labels_mnist.extend([c] * mus_mnist[-1].shape[0])\n",
    "\n",
    "mus_mnist = np.concatenate(mus_mnist, axis=0)\n",
    "labels_mnist = np.array(labels_mnist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=20, min_dist=0.1, random_state=42)\n",
    "embedding = reducer.fit_transform(np.array(mus_mnist))\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(x=embedding[:,0], y=embedding[:,1], hue=labels_mnist, palette=\"tab10\")\n",
    "plt.title(\"VAE MNIST Latent Space UMAP Projection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Configuration\n",
    "classes = np.unique(labels_mnist)\n",
    "bandwidth = None  # let gaussian_kde choose (Scott's rule)\n",
    "grid_res = 200\n",
    "\n",
    "# Fix plot limits so geometry is comparable across runs\n",
    "x_min, x_max = embedding[:, 0].min(), embedding[:, 0].max()\n",
    "y_min, y_max = embedding[:, 1].min(), embedding[:, 1].max()\n",
    "\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, grid_res),\n",
    "    np.linspace(y_min, y_max, grid_res)\n",
    ")\n",
    "grid = np.vstack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter points (faint, for reference)\n",
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=labels_mnist,\n",
    "    s=6,\n",
    "    cmap=\"tab10\",\n",
    "    alpha=0.25\n",
    ")\n",
    "\n",
    "# KDE contours per class\n",
    "for c in classes:\n",
    "    mask = labels_mnist == c\n",
    "    points = embedding[mask].T  # shape (2, Nc)\n",
    "\n",
    "    if points.shape[1] < 10:\n",
    "        continue  # KDE not stable with very few points\n",
    "\n",
    "    kde = gaussian_kde(points, bw_method=bandwidth)\n",
    "    density = kde(grid).reshape(xx.shape)\n",
    "\n",
    "    plt.contour(\n",
    "        xx, yy, density,\n",
    "        levels=5,\n",
    "        linewidths=1,\n",
    "        alpha=0.9\n",
    "    )\n",
    "\n",
    "plt.title(\"Class-conditional KDE over VAE latent UMAP\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c181ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "datasets_cfg = {\n",
    "    \"mnist\": {\n",
    "        \"data\": test_mnist,\n",
    "        \"vae\": vae_mnist,\n",
    "        \"ckpt\": \"mnist_head_10.pth\",\n",
    "        \"num_classes\": 10,\n",
    "    },\n",
    "    \"kmnist\": {\n",
    "        \"data\": test_kmnist,\n",
    "        \"vae\": vae_kmnist,\n",
    "        \"ckpt\": \"kmnist_head_10.pth\",\n",
    "        \"num_classes\": 10,\n",
    "    },\n",
    "    \"fashion_mnist\": {\n",
    "        \"data\": test_fashion_mnist,\n",
    "        \"vae\": vae_fashion_mnist,\n",
    "        \"ckpt\": \"fashion_mnist_head_10.pth\",\n",
    "        \"num_classes\": 10,\n",
    "    },\n",
    "    \"hebrew_chars\": {\n",
    "        \"data\": train_hebrew_chars,\n",
    "        \"vae\": vae_hebrew_chars,\n",
    "        \"ckpt\": \"hebrew_chars_head_10.pth\",\n",
    "        \"num_classes\": 20,\n",
    "    },\n",
    "    \"math_shapes\": {\n",
    "        \"data\": test_math_shapes,\n",
    "        \"vae\": vae_math_shapes,\n",
    "        \"ckpt\": \"math_shapes_head_10.pth\",\n",
    "        \"num_classes\": 8,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ba353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_for_dataset(\n",
    "    data,\n",
    "    vae,\n",
    "    ckpt_path,\n",
    "    samples_per_class=500,\n",
    "    device=\"cuda\",\n",
    "    umap_kwargs=None,\n",
    "):\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    vae.load_state_dict(ckpt[\"hyper_state_dict\"])\n",
    "    vae.to(device)\n",
    "    vae.eval()\n",
    "\n",
    "    mus = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for c in sorted(df[\"label\"].unique()):\n",
    "            rows = df[df[\"label\"] == c]\n",
    "\n",
    "            if samples_per_class is not None:\n",
    "                rows = rows.sample(\n",
    "                    n=min(samples_per_class, len(rows)),\n",
    "                    random_state=42,\n",
    "                )\n",
    "\n",
    "            imgs = np.stack(rows[\"image\"].values)\n",
    "            imgs = (\n",
    "                torch.tensor(imgs)\n",
    "                .unsqueeze(1)\n",
    "                .float()\n",
    "                .to(device) / 255.0\n",
    "            )\n",
    "\n",
    "            _, mu, _ = vae(imgs)\n",
    "            mu = mu.cpu().numpy()\n",
    "\n",
    "            mus.append(mu)\n",
    "            labels.extend([c] * mu.shape[0])\n",
    "\n",
    "    mus = np.concatenate(mus, axis=0)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=20,\n",
    "        min_dist=0.1,\n",
    "        random_state=42,\n",
    "        **(umap_kwargs or {}),\n",
    "    )\n",
    "\n",
    "    embedding = umap_model.fit_transform(mus)\n",
    "\n",
    "    return embedding, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "base_ckpt_dir = Path().resolve().parent / \"models\"\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "\n",
    "for ax, (name, cfg) in zip(axes, datasets_cfg.items()):\n",
    "    emb, labels = umap_for_dataset(\n",
    "        data=cfg[\"data\"],\n",
    "        vae=cfg[\"vae\"],\n",
    "        ckpt_path=base_ckpt_dir / cfg[\"ckpt\"],\n",
    "        samples_per_class=200,\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        emb[:, 0],\n",
    "        emb[:, 1],\n",
    "        c=labels,\n",
    "        s=5,\n",
    "        cmap=cmap,\n",
    "    )\n",
    "\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # ---- per-axis legend ----\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    legend_handles = [\n",
    "        Line2D(\n",
    "            [0], [0],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"\",\n",
    "            markersize=6,\n",
    "            markerfacecolor=cmap(c / max(unique_labels)),\n",
    "            markeredgecolor=\"none\",\n",
    "            label=str(c),\n",
    "        )\n",
    "        for c in unique_labels\n",
    "    ]\n",
    "\n",
    "    ax.legend(\n",
    "        handles=legend_handles,\n",
    "        title=\"Class\",\n",
    "        loc=\"best\",\n",
    "        fontsize=8,\n",
    "        title_fontsize=9,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903a2ea",
   "metadata": {},
   "source": [
    "### TARGET NETWORK EMBEDDING OVER TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd44fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"target_embeddings_over_time.pt\", map_location=\"cpu\")\n",
    "\n",
    "# sort epochs\n",
    "epochs = sorted(data.keys())\n",
    "print(f\"Loaded embeddings for {len(epochs)} epochs:\")\n",
    "print(epochs[:5], \"...\", epochs[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fcddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_embs = np.concatenate(\n",
    "    [data[e][\"embeddings\"].numpy() for e in epochs],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "# compute global limits with a small margin\n",
    "margin = 0.05\n",
    "x_min, x_max = all_embs[:, 0].min(), all_embs[:, 0].max()\n",
    "y_min, y_max = all_embs[:, 1].min(), all_embs[:, 1].max()\n",
    "\n",
    "x_pad = (x_max - x_min) * margin\n",
    "y_pad = (y_max - y_min) * margin\n",
    "\n",
    "X_LIM = (x_min - x_pad, x_max + x_pad)\n",
    "Y_LIM = (y_min - y_pad, y_max + y_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "unique_labels = np.unique(data[epochs[0]][\"labels\"].numpy())\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "label_to_color = {lab: cmap(lab) for lab in unique_labels}\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D(\n",
    "        [0], [0],\n",
    "        marker='o',\n",
    "        color='w',\n",
    "        label=f\"Class {lab}\",\n",
    "        markerfacecolor=label_to_color[lab],\n",
    "        markersize=6\n",
    "    )\n",
    "    for lab in unique_labels\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "def update(i):\n",
    "    ax.clear()\n",
    "\n",
    "    epoch = epochs[i]\n",
    "    emb = data[epoch][\"embeddings\"].numpy()\n",
    "    labels = data[epoch][\"labels\"].numpy()\n",
    "\n",
    "    for lab in unique_labels:\n",
    "        mask = labels == lab\n",
    "        ax.scatter(\n",
    "            emb[mask, 0],\n",
    "            emb[mask, 1],\n",
    "            s=8,\n",
    "            color=label_to_color[lab],\n",
    "            alpha=0.8\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(*X_LIM)\n",
    "    ax.set_ylim(*Y_LIM)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    ax.set_title(f\"Target embedding geometry â€“ epoch {epoch}\")\n",
    "    ax.set_xlabel(\"dim 1\")\n",
    "    ax.set_ylabel(\"dim 2\")\n",
    "    ax.legend(handles=legend_elements, loc=\"best\", fontsize=8)\n",
    "    ax.grid(True)\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=len(epochs),\n",
    "    interval=100,\n",
    "    blit=False\n",
    ")\n",
    "\n",
    "ani.save(\n",
    "    \"geometry_evolution_labeled.mp4\",\n",
    "    fps=10,\n",
    "    dpi=150,\n",
    "    writer=\"ffmpeg\"\n",
    ")\n",
    "\n",
    "plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UDL-MetaTrainingHyperNetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
