training:
  batch_size_outerloop: 16
  batch_size_innerloop: 16
  batch_size_vae: 256

  epochs_hyper: 1000
  epochs_vae: 100

  lr_hyper: 1e-4
  lr_vae: 1e-4
  lr_target: 5e-3

  log_interval: 40
  save_path: "hypernet_checkpoint.pth"

meta:
  steps_innerloop: 5
  steps_outerloop: 3

data:
  image_width_height: 28
  num_classes: 4

vae:
  vae_head_dim: 10
  n_samples_conditioning: 100
  retrain_vae: false
  vae_description: "_head_10"

model:
  cluster_using_guassians: true
  use_contrastive_loss: true
  contrastive_temp: 0.07

hypernet:
  head_hidden: 256
  use_bias: true

target_net:
  # If cluster_using_guassians=true, input_dim is 2*vae_head_dim (mu + logvar)
  # Else, input_dim is image_width_height^2 (flattened image)
  hidden_layers: [400, 200]
  output_head: 10
